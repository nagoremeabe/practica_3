{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "from scipy.stats.stats import pearsonr\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import numpy.ma as ma\n",
    "import numpy.linalg as linalg\n",
    "from scipy import signal\n",
    "import xarray as xr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region(data,lat,lon,lonmin,lonmax,latmin,latmax):\n",
    "    # data[t,lon,lat]\n",
    "    latc=lat[(lat>=latmin)&(lat<=latmax)]\n",
    "    lonc=lon[(lon>=lonmin)&(lon<=lonmax)]\n",
    "    datac = data[:,:,(lon>=lonmin)&(lon<=lonmax)][:,(lat>=latmin)&(lat<=latmax),:]\n",
    "    return datac,latc,lonc\n",
    "\n",
    "def season(Z,e1,e2,nyrs):\n",
    "# para que funcione los datos Z tienen que estar con dimensiones nyrs,12,ns\n",
    "# e1 y e2 son los meses inicial y final de las estaciones\n",
    "# e1=2;e2=4 ;esta='MAM';\n",
    "# e1=5;e2=7 ;esta='JJA';\n",
    "# e1=6;e2=8 ;esta='JAS';\n",
    "# e1=8;e2=10 ;esta='SON';\n",
    "# e1=11;e2=1 ;esta='DJF';\n",
    "# e1=10;e2=1 ;esta='NDJF';\n",
    "   \n",
    "    if e1==11:\n",
    "        Zs1= Z[:-1,e1,:]\n",
    "        Zs2= Z[1:,:e2,:].mean(1)\n",
    "        n1=1\n",
    "        n2=e2+1\n",
    "        Zs=(Zs1*n1+Zs2*n2)/(n1+n2)\n",
    "        nyrs=nyrs-1\n",
    "    elif e1>e2:\n",
    "        Zs1= Z[:-1,e1:11,:].mean(1)\n",
    "        Zs2= Z[1:,:e2,:].mean(1)\n",
    "        n1=12-e1\n",
    "        n2=e2+1\n",
    "        Zs=(Zs1*n1+Zs2*n2)/(n1+n2)\n",
    "        nyrs=nyrs-1\n",
    "    else:\n",
    "        Zs = Z[:,e1:e2,:].mean(1)\n",
    "\n",
    "    return Zs ,nyrs\n",
    "\n",
    "def anom(X,nyr,par):\n",
    "#si par = st quiere decir que estandarizo. Si no, no (pongo, por ejemplo,'pp')\n",
    "    ns,nt=np.shape(X) #una de las dimensiones es tiempo, la segunda, y la otra puede ser el numero de modos, o de espacios..\n",
    "    nmes=np.int(nt/(nyr));\n",
    "    #nmes=1\n",
    "#dividimos el número de tiempos por el numero de años porque en caso de que queramos calcular\n",
    "#anomalias estacionales de una secuencia mensual (enero-media(diciembre-enero-febrero)) en lugar de una media estacional\n",
    "\n",
    "    An=ma.empty([ns,nt])\n",
    "\n",
    "    for i in range(ns):\n",
    "        A= X[i,:].reshape(nyr,nmes)\n",
    "        mA=np.mean(A)\n",
    "        for j in range(0,nyr):\n",
    "            A[j,:]=A[j,:]-mA\n",
    "        \n",
    "        if  par=='st':\n",
    "            \n",
    "            stdA=ma.empty([nmes,])\n",
    "            for k in range(nmes):\n",
    "                stdA[k]=np.std(A[:,k])\n",
    "                if stdA[k]!=0:\n",
    "                    A[:,k]=A[:,k]/stdA[k]\n",
    "    \n",
    "\n",
    "#se reorganizan los datos\n",
    "        A=np.transpose(A.reshape(nyr*nmes,1))\n",
    "        An[i,:]=A;\n",
    "              \n",
    "    return An"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujo_1_mapa_cartopy(A,lon,lat, levs, cmap1, l1):\n",
    "\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(0))\n",
    "\n",
    "    im = ax.contourf(lon,lat,A.reshape(len(lat),len(lon))\n",
    "                 ,cmap=cmap1,levels=levs,extend='both',transform = ccrs.PlateCarree())\n",
    "    ax.coastlines(linewidth=2); \n",
    "    fig.colorbar(im,ax=ax,label = l1) #Para la barra de colores\n",
    "    \n",
    "# Esta función te sirve para dibujar en una misma figura dos mapas superpuestos, como podría ser\n",
    "# el caso de un mapa A de regresion y un mapa B de correlacion significativa, del que solo te interesa\n",
    "# las regiones donde es significativa la señal\n",
    "def dibujo_2_mapas_cartopy_hatches(A,B,lon,lat, levs, cmap1, l1, t1):\n",
    "\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(0))\n",
    "    \n",
    "    im = ax.contourf(lon,lat,A.reshape(len(lat),len(lon)), \n",
    "                     extend='both',cmap=cmap1,levels=levs,transform = ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines(linewidth=2); \n",
    "    fig.colorbar(im,ax=ax,label = l1) #Para la barra de colores\n",
    "    im = ax.contourf(lon,lat,B.reshape(len(lat),len(lon))\n",
    "                 ,extend='both'\n",
    "                 ,hatches='.',cmap=cmap1,alfa=0,levels=levs,transform = ccrs.PlateCarree())\n",
    "    #el uso de alfa=0 lo que hace es que solo salgan los puntos y no salgan los colors porque los pones totalmente transparentes\n",
    "    # si el mapa significativo abarca una región menor suele cortarlo\n",
    "    # para ello añadimos estos límites\n",
    "    ax.set_ylim(lat[-1], lat[0])\n",
    "    ax.set_xlim(lon[0], lon[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función calcula correlaciones en datos de mas de una dimensión\n",
    "# util en indexredrcorr\n",
    "def pearsonr_2D(y, x):\n",
    "    upper = np.sum((x - np.mean(x)) * (y - np.mean(y, axis=1)[:,None]), axis=1)\n",
    "    lower = np.sqrt(np.sum(np.power(x - np.mean(x), 2)) * np.sum(np.power(y - np.mean(y, axis=1)[:,None], 2), axis=1))\n",
    "    rho = upper / lower\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misma que index regresión pero algo mas intuitiva\n",
    "def IndexRegrCorr(Data,Index,alfa,sig,pp):\n",
    "    try:\n",
    "        [ns,nt]=Data.shape # n1=espacio, n2=tiempo\n",
    "    except ValueError:\n",
    "        # si Data es un índice\n",
    "        ns=1\n",
    "        nt=len(Data)\n",
    "        Data = np.array([Data])\n",
    "        \n",
    "    cor=ma.empty([ns,])\n",
    "    Pvalue=ma.empty([ns,])\n",
    "    reg=np.dot(Data,Index)/(nt-1)\n",
    "\n",
    "    # MUY IMPORTANTE!!!\n",
    "    # Index tiene que ser una serie de datos estandarizada\n",
    "    for nn in range(ns): \n",
    "        bb=pearsonr(Data[nn,:],Index) \n",
    "        cor[nn]=bb[0]\n",
    "        Pvalue[nn]=bb[1]\n",
    "\n",
    "    if sig == 'test-t':\n",
    "        cor_sig=ma.masked_where(Pvalue>alfa,cor)\n",
    "        reg_sig=ma.masked_where(Pvalue>alfa,reg)\n",
    "        \n",
    "    if sig == 'MonteCarlo':\n",
    "        corp = ma.empty([ns,pp])\n",
    "        for p in range(pp):\n",
    "            corp[:,p] = pearsonr_2D(Data,np.random.permutation(Index))\n",
    "            # aquí uso la función pearsonr_2D y me ahorro un bucle en ns\n",
    "        \n",
    "        for nn in range(ns): \n",
    "            hcor = np.count_nonzero((cor[nn]>0)&(corp[nn,:]<cor[nn])|(cor[nn]<0)&(corp[nn,:]>cor[nn]))\n",
    "            # nivel de confianza\n",
    "            Pvalue[nn] = hcor/pp\n",
    "            \n",
    "        cor_sig = ma.masked_where(Pvalue<(1-alfa),cor)\n",
    "        reg_sig = ma.masked_where(Pvalue<(1-alfa),reg)\n",
    "        \n",
    "    return cor, Pvalue, cor_sig, reg,reg_sig\n",
    "\n",
    "    # correlacion y regresion significativo son mapas con un p value\n",
    "    # menor al impuesto por nosotros\n",
    "    # cuando es mayor no los enseñara y los hará mascara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para operar con nans\n",
    "def quitonans(mat):\n",
    "    out = mat[:,~np.isnan(mat.mean(axis = 0))]\n",
    "    return out\n",
    "\n",
    "def pongonans(matred,mat):\n",
    "    out = mat.mean(axis = 0 )\n",
    "    out[:] = np.nan\n",
    "    out[~np.isnan(mat.mean(axis = 0))] = matred\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCA(Z,Y,nmes,nm,meth,alfa,sig,perm):\n",
    "    # Z: campo a predecir\n",
    "    # Y: campo predictor\n",
    "    # datos con dimensiones ns, nt\n",
    "    # nm: numero de modos\n",
    "    # nmes: meses por año, si es media estacional es 1, pero si es enero y feb\n",
    "    # por separado es 2\n",
    "    # meth: metodología\n",
    "    # Y1, Z1: campos sobre los que proyecto los resultados, \n",
    "    #que pueden ser para un espacio mayor que en Z e Y\n",
    "    \n",
    "    nz,nt=Z.shape\n",
    "    ny,nt=Y.shape\n",
    "    nyr=int(nt/nmes)\n",
    "    # matriz de covarianza\n",
    "    if  meth=='MCA':\n",
    "        C=np.dot(Y,np.transpose(Z))\n",
    "    \n",
    "    if  meth =='CCA': # matriz de covarianza\n",
    "        iSYY=inv(np.dot(Y,np.transpose(Y)))\n",
    "        SYZ=np.dot(Y,np.transpose(Z))\n",
    "        iSZZ=inv(np.dot(Z,np.transpose(Z)))\n",
    "        SZY=np.dot(Z,np.transpose(Y))\n",
    "        C=np.dot(np.dot(iSYY,SYZ), np.dot(iSZZ,SZY))\n",
    "    \n",
    "    R,d,Q=linalg.svd(C)\n",
    "    scf=d/np.sum(d) # fraccion de covarianza explicada\n",
    "\n",
    "    # coefs de expansión, protectamos sobre los primeros nm \n",
    "    # obtenemos unas series temporales\n",
    "    U=np.dot(np.transpose(Y),R[:,:nm])\n",
    "    V=np.dot(np.transpose(Z),Q[:,:nm])\n",
    "    \n",
    "    # coefs de expansión estandarizados\n",
    "    # estandarizamos esas series temporales\n",
    "    Us = anom(np.transpose(U),nyr,'st')\n",
    "    Vs = anom(np.transpose(V),nyr,'st')\n",
    "    \n",
    "    # mapas de regresión en ambos casos se usa U y no V !! (serie temporal U)\n",
    "    RUY = ma.empty([ny,nm]);pvalruy=ma.empty([ny,nm]);RUY_sig=ma.empty([ny,nm]);SUY=ma.empty([ny,nm]);SUY_sig=ma.empty([ny,nm])\n",
    "    RUZ = ma.empty([nz,nm]);pvalruz=ma.empty([nz,nm]);RUZ_sig=ma.empty([nz,nm]);SUZ=ma.empty([nz,nm]);SUZ_sig=ma.empty([nz,nm])\n",
    "    \n",
    "    # proyrctamos los datos sobre los primeros nm autovalores\n",
    "    for i in range(nm):\n",
    "        RUY[:,i], pvalruy[:,i], RUY_sig[:,i], SUY[:,i], SUY_sig[:,i]=IndexRegrCorr(Y,Us[i,:],alfa,sig,perm)\n",
    "        RUZ[:,i], pvalruz[:,i], RUZ_sig[:,i], SUZ[:,i], SUZ_sig[:,i]=IndexRegrCorr(Z,Us[i,:],alfa,sig,perm)\n",
    "    \n",
    "    # MAPA DE CORRELACION SOBRE Y Y Z\n",
    "    return RUY, RUY_sig, SUY, SUY_sig, RUZ, RUZ_sig, SUZ, SUZ_sig, Us, Vs, scf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro(nyc,n,Wn,TS):\n",
    "    '''\n",
    "    nyc: periodo\n",
    "    n  :\n",
    "    wn : frecuencia de corte 2*dt/nyc\n",
    "    TS :\n",
    "    '''\n",
    "# Wn= \n",
    "    b,a=signal.butter(n, Wn, btype='low', analog=False, output='ba', fs=None)\n",
    "    # Filtro la señal ampliada y me quedo con la parte central:\n",
    "    low = signal.filtfilt(b,a,TS)\n",
    "    b,a=signal.butter(n, Wn, btype='high', analog=False, output='ba', fs=None)\n",
    "    # Filtro la señal ampliada y me quedo con la parte central:\n",
    "    high = signal.filtfilt(b,a,TS)\n",
    "    return high, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujo_timeserie(ax,TS,time,ylabel,xlabel,title):\n",
    "    '''\n",
    "    '''\n",
    "    ax.plot(time,TS,linewidth=6)\n",
    "    ax.grid(b=True, linestyle ='--')\n",
    "    plt.xticks(np.arange(time[0],time[-1],20))\n",
    "    ax.tick_params('y',labelsize = 14, width = 2, length = 10)\n",
    "    ax.tick_params('x',labelsize = 12, width = 2, length = 10, labelrotation = 60)\n",
    "    ax.legend(loc=3,fontsize=14)\n",
    "    ax.set_title(title, fontsize = 16, weight ='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize = 14, fontweight = 'bold')\n",
    "    ax.set_xlabel(xlabel, fontsize = 14, fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujo_timeserie_confiltro(ax,time,sig,low,low_det,high,xlabel,ylabel,title):\n",
    "    ax.plot(time,sig,label ='raw')\n",
    "    ax.plot(time,low,label ='low')\n",
    "    ax.plot(time,high,label ='high')\n",
    "    ax.plot(time,low_det,label ='low_det')\n",
    "    ax.grid(b=True, linestyle ='--')\n",
    "    plt.xticks(np.arange(time[0],time[-1],20))\n",
    "    ax.tick_params('y',labelsize = 14, width = 2, length = 10)\n",
    "    ax.tick_params('x',labelsize = 12, width = 2, length = 10, labelrotation = 60)\n",
    "    ax.legend(loc=3,fontsize=14)\n",
    "    ax.set_title(title, fontsize = 16, weight ='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize = 14, fontweight = 'bold')\n",
    "    ax.set_xlabel(xlabel, fontsize = 14, fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(Y,Z,nmes,nm,alfa,sig,perm):\n",
    "    '''\n",
    "    Técnica utilizada para predicción que se explicará más adelantes\n",
    "    '''\n",
    "    #Y campo predictor\n",
    "    # Z campo a predecir\n",
    "    # nmes: numero de tiempos por año (numero de meses o de días), normalmente es 1 porque se hacen promedios estacionales\n",
    "    # alfa: nivel de significacion: 0.01,0.05,0.1\n",
    "    #sig: \"t-test\" si la significacion de los modos se hace por un test de independencia de caracteres con test-t, \"MonteCarlo\", \n",
    "    #si se hace con un test no paramétrico de MonteCarlo con un número perm de permutaciones (100, 200 etc..)\n",
    "    \n",
    "    nz,nt = Z.shape\n",
    "    ny,nt = Y.shape\n",
    "    \n",
    "    Zhat = ma.empty_like(Z)\n",
    "    scf = ma.empty([ny,nt])\n",
    "    ruv = ma.empty([nm,nt])\n",
    "    pruv = ma.empty([nm,nt])\n",
    "    # estimación de Zhat para cada año\n",
    "    yrs=np.linspace(1,nt,nt)\n",
    "    for i in range(nt):\n",
    "        print(i)\n",
    "        z2 = Z[:,yrs!=i]\n",
    "        y2 = Y[:,yrs!=i]\n",
    "        RUY,RUY_sig,SUY,SUY_sig,RUZ,RUZ_sig,SUZ,SUZ_sig,Us,Vs,scf[:,i] = MCA(z2,y2,nmes,nm,'MCA',alfa,sig,perm)\n",
    "        PSI=np.dot(np.dot(np.dot(SUY,linalg.inv(np.dot(Us,np.transpose(Us)))),Us),np.transpose(z2))*nt*nm/ny \n",
    "        Zhat[:,i] = np.dot(np.transpose(Y[:,i]),PSI)\n",
    "        for m in range(nm):\n",
    "            ruv[m,i],pruv[m,i] = pearsonr(Us[m,:],Vs[m,:])\n",
    "    \n",
    "    r = np.zeros(nt)       \n",
    "    for j in range(nt):\n",
    "        r[j] = pearsonr(Zhat[:,j],Z[:,j])[0] # serie de skill\n",
    "      \n",
    "    rs = np.zeros(nz) \n",
    "    rs_sig = np.zeros(nz) \n",
    "    rmse = np.zeros(nz)\n",
    "  \n",
    "    for j in range(nz):\n",
    "        rs[j] = pearsonr(Zhat[:,j],Z[:,j])[0] # serie de skill\n",
    "  \n",
    "        \n",
    "    return Zhat,scf,ruv,r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de extremos anomala (campo a predecir) -  cold nights\n",
    "folder = 'data/Tn10p_ESP_nan.nc'\n",
    "ds     = xr.open_dataset(folder)\n",
    "\n",
    "# selecciono la latitud y longitud\n",
    "lon = ds.x\n",
    "lat = ds.y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campo Predictor: *SLP*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# campo predictor SLP\n",
    "folder_1 = '..\\..\\data\\ERA\\slp_ERA20_1900-2010.nc'\n",
    "ds     = xr.open_dataset(folder_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campo Predictor: *SST*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_analisis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43e0026a026c617cfd77bb65abdfe6b37e98f3574356d3c346960f6783f3e552"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
